<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Electric Python]]></title>
  <link href="http://NigelCleland.github.io/atom.xml" rel="self"/>
  <link href="http://NigelCleland.github.io/"/>
  <updated>2013-06-01T18:13:41+12:00</updated>
  <id>http://NigelCleland.github.io/</id>
  <author>
    <name><![CDATA[Nigel Cleland]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Experimenting with Flask and Web Development]]></title>
    <link href="http://NigelCleland.github.io/blog/2013/06/01/experimenting-with-flask-and-web-development/"/>
    <updated>2013-06-01T18:09:00+12:00</updated>
    <id>http://NigelCleland.github.io/blog/2013/06/01/experimenting-with-flask-and-web-development</id>
    <content type="html"><![CDATA[<p>I&rsquo;m currently experimenting with using Flask for a bit of Web Development.
I&rsquo;ve never done web dev before and it has been an interesting learning experience so far. I&rsquo;m going to create a fairly simple tracking app for the gym etc, basically get a Database set up and some logging going on.</p>

<!-- more -->


<p>Once this is done, I&rsquo;ll try and extend it and get some fancier features going on, visualisations etc. It will be interesting working with these to see how python can be used in such a fashion. May end up dictating some of the other work I do as well which I may want to expose via websites.</p>

<p>This post is currently a work in progress</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[What I'm currently working on]]></title>
    <link href="http://NigelCleland.github.io/blog/2013/05/27/what-im-currently-working-on/"/>
    <updated>2013-05-27T19:52:00+12:00</updated>
    <id>http://NigelCleland.github.io/blog/2013/05/27/what-im-currently-working-on</id>
    <content type="html"><![CDATA[<p>Haven&rsquo;t been able to write as much as I would have liked to over the past week. Been a bit tied up with other things going on. Thus, I thought I&rsquo;d take this opportunity to run through each of the various projects and research lines I&rsquo;m going down at the moment. Hopefully this should be a bit of an overview as to what I actually do.</p>

<p>Broadly I&rsquo;ll divide my projects into three categories, write up stage, in progress stage and backburner stage. A project in write up stage is currently undergoing final revisions before submission to journals/conferences etc. Ones in the in progress stage are what I&rsquo;m currently actively developing. This includes a lot of experimentation and prototyping to help consolidate my thoughts. Finally, the ones on the backburner stage are those which I&rsquo;m currently thinking about and will tackle when I get time.</p>

<!-- more -->


<h2>Write up Stage</h2>

<h3>Reserve Constraints in co-optimised energy and security markets</h3>

<p>My first major piece of work which started it all. In an energy and reserve co-optimised market the total least cost solution for energy and security are dispatched. However, this can result in some quite non-intuitive dispatches and final pricing which is difficult to understand.
In particular, the merit order appears to be broken and final pricing can become disconnected from the energy offers.</p>

<p>This body of work discusses the theoretical mechanism through which this occurs. These theoretical mechanisms can be developed in two separate ways. Using the associate dual program (to the primal dispatch problem) or by developing small models which have a small subset of the constraints applied. I prefer the second approach as it is quite intuitive when visualising the solution upon a small model as compared to the mathematical result which arises. These constraints can occur in a number of different ways, and corner point solutions are also possible.</p>

<p>Finally, I apply the results to create a set of filters which can be applied to the New Zealand market to determine when constraints occur.
These filters are extremely effective (although transmission losses are an issue) at identifying the vast majority of the constrained periods. These results are illustrated as well as some discussion regarding the effect upon average prices discussed. The broad results is that security co-optimisation does not lead to any noticeable (long term) effect on energy prices although seasonal effects are apparent. However, these constraints have a major effect upon the average reserve market price and their resolution may severely reduce such pricing.</p>

<h3>Probabilistic models for assessing the frequency of reserve constrained events.</h3>

<p>This is a body of work which extends upon the reserve constraints I identified above. Broadly, it seeks to investigate the common causes and if possible develop a probabilistic approach to investigating when they might occur. Broadly, I assess the general factors which are related in Electricity markets, time of day, time of year, hydrology, demand, security availability and market risk. From these factors I choose a subset which I then develop into an extended model.</p>

<p>The model used inverse weighting of two smaller, more generic predictions. The inverse weighting method is used due to a dichotomy in the number of periods which exist at different hydrology levels. Using discrete bin sizes would lead to large errors and horribly distort the model. However, it was non-intuitive as to the best method of rectifying this. I settled on the inverse weighting approach as it appeared simple and elegant and accurately addressed my major concern.</p>

<p>The model develop shows great qualitative and adequate quantitative accuracy. These events in New Zealand are uncommon, happening between 2% and 10% of the total trading periods over the past five years (South Island market, North Island market respectively). Thus, any approach would provides an indication as to when they occur is very useful. Broadly, the model was able to predict when large numbers of constrained periods would occur, as well as when they would not. Such a result is a definitive increase compared to a simple naive average, furthermore it is an enhanced understanding over the raw (univariate) analysis initially conducted.</p>

<h3>On the non-linearity of consequences, why low probability events matter in Electricity networks.</h3>

<p>This is a short extended abstract and presentation which I&rsquo;m preparing for the U21 graduate conference in Dublin. The theme of the conference is Energy Policy and Systems. In this vein I&rsquo;ve decided to not speak about security constrained events and to take a more philosophical approach. One line of thought which I find fascinating is that some events are so catastrophic, so disastrous that people would pay almost any price to avoid them.</p>

<p>I extend this idea into the realm of Electricity markets and develop several case studies. These case studies explore the broad elements of non-linearity in bounded systems (e.g. how the system behaves as it approaches the bound, as well as the location of each bound) and discuss their importance. It is also extend to develop a non-linear tolerance between different participants in a system to highlight a dichotomy. The broad case studies discussed are:</p>

<ul>
<li>Cascade failure in Electrical networks leading to black starts</li>
<li>Extreme price distributions, 53% of revenue in the NZ security (secondary) market is made in 1% of the trading periods</li>
<li>Response to the Christchurch Earthquake of 2011 which highlighted different participants tolerance to network disruption.</li>
</ul>


<h2>In Progress Stage</h2>

<h3>Hedging via Reserve Markets</h3>

<p>This is an idea which I&rsquo;m currently developing regarding the effectiveness of partial hedging via the reserve markets. Broadly, such a measure is similar to a Financial Transmission Right (FTR). However, an FTR is far more comprehensive than the Reserve Hedge. The pertinent question to be answered would be the relative effectiveness of such a measure. This effectiveness will likely be measured by assessing the degree of cover afforded by such a hedge as well as the relative cost of such a measure.</p>

<p>I may be able to incorporate my probabilistic work into this to extend it into a dynamic hedging strategy. This could be undertaken along both perfect (full information and ability to hedge) and imperfect (heavily constrained) viewpoints. Either way, it will be an interesting assessment of how reserve markets can be linked into the energy markets. One measure which is not covered is that reserve hedging could be accomplished either physically or financially.</p>

<h2>Backburner Stage</h2>

<h3>Offer Strategies for participants during reserve constrained events.</h3>

<p>This will be more of a theoretical evaluation as to how optimal offer strategies begin to change when Reserve constraints are present in a market. These constraints will be assessed from a number of view points, e.g. generator, generator with reserve, reserve provider etc as to determine what the effect is on the margin. As there exists a linkage between the energy and reserve market prices during these events. Thus, it may be possible to highlight when a participant may be able to exert market power in one market to induce a constraint resulting in increased profits.</p>

<h3>Simulation study of the effect of reduced Transmission constraints upon Reserve and Enerfy pricing in New Zealand.</h3>

<p>My current body of work has shown that there exists a substantial relationship between the value of the security market and constraints. Broadly, the market is defined by extremely low median prices with very high priced tail events which occur extremely rarely. However, these events are linked to constraints which exist due to the configuration of the HVDC poles. With the commissioning of the new Pole it will be worthwhile to assess what effect this will have upon the marginal periods when electricity peakers and reserve providers expect to recover the majority of their costs.</p>

<h2>Code Projects</h2>

<h3>nzem</h3>

<p>This is intended mainly as a personal repository, but I will attempt to make it usable for others, which should investigate the ease of investigating the NZ electricity market. It currently has some broad helper functions but is currently in a bit of a haphazard space and needs a full rework soon. I&rsquo;ll try and put together a longer post explaining where I&rsquo;m intending to take this as well as highlighting what work needs to be done soon.</p>

<p>I also want to extend this module to help assess the NZ electricity hedge market including a better method of handling the data import and output. I&rsquo;ll attempt to get this started as soon as possible.</p>

<h3>pdtools</h3>

<p>pdtools is a repository which applies a few monkey patches to the Pandas DataFrame and Series objects. Currently it adds some useful (in my opinion) data selection functions to both DataFrames and Series as well as providing method to simplify merging series. This repository will contain the functions and shortcuts I find most useful when working with Pandas objects.</p>

<p>One thing which I do want to extend with this library is making the plotting and data output slightly nicer for including in publications. I find the default matplotlib styles a little ho-hum so I&rsquo;ll try and build some improve functionality into the repository to make the plots prettier. One other aspect is that I prefer a particular LaTeX table style when I&rsquo;m putting together tables so I&rsquo;ll include this as well.</p>

<h3>pyspd</h3>

<p>pyspd is a small repository which is intended to create small linear programs with the full complement of security and risk constraints in the NZ market. Broadly, it provides wrappers for setting up Nodes and generation stations without needing to understand how the underlying mathematics work. To do this it builds upon the puLP repository and the relevant solvers will be needed.</p>

<p>Currently this repository needs a lot of work to bring it up to scratch in the near future.</p>

<h2>Conclusion</h2>

<p>Well, this broadly covers everything I&rsquo;m working on professionally at the moment. There are a number of things which require my attention and it can be difficult juggling the time appropriately between them. In particular, I find when I get in a state of flow that I can crank out a large volume of highly productive and high quality work in a few hours. However, if I can&rsquo;t reach this state then it is difficult to be productive. One thing I&rsquo;m working on is trying to queue up work which can be done in less productive states (i.e. requiring little creativity or insight) so that I can still get things done. However, I appear to have had limited success at doing this so far.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Why Researchers should strive to develop repeatable code]]></title>
    <link href="http://NigelCleland.github.io/blog/2013/05/20/why-researchers-should-strive-to-develop-repeatable-code/"/>
    <updated>2013-05-20T11:06:00+12:00</updated>
    <id>http://NigelCleland.github.io/blog/2013/05/20/why-researchers-should-strive-to-develop-repeatable-code</id>
    <content type="html"><![CDATA[<p>As a researcher you&rsquo;ll often have to conduct a lot of smaller experiments, testing out a hypothesis here, running some data analysis there. Yet a lot of people I know, and I am personally guilty of this as well, do not make these scripts repeatable. Writing smart, testable, repeatable code takes longer and for many researchers who code out of necessity, not out of love it is not as intuitive. In many undergraduate degrees, particularly in engineering, the goal throughout the course of study is more to finish the assignment, pass the paper and repeatability be damned.</p>

<p>However, this behaviour becomes counterproductive once you start researching. I cannot imagine the number of hours I have wasting having to repeat useless boiler plate, hard coded examples when some intelligent preparation work, although taking a bit longer initially would save me far more time in the long run.</p>

<!-- more -->


<p>The temptation is to justify taking the quick route through the rational realisation that a lot of the code you write will often be thrown away. Therefore, what is the point in making sure it is repeatable if we may throw out the hypothesis and start again anyway? Here, focus upon the methods you are applying, know that data you are applying it to and take a couple lessons from functional programming.</p>

<p>For example, you may create a great hypothesis which works for your current set of data. However, you&rsquo;ve screwed up and hard coded a bunch of exceptions, magic numbers and other such parameters into the code. Elements you didn&rsquo;t need to. Wouldn&rsquo;t it be great if you could simply point your magical, world breaking, code at a new source of data and let the computer sort it all out?</p>

<p>In my opinion this is what researchers should be striving to do. To separate content and form so to speak from one another. If you are developing a model, generalise the parts of it and then set it up so they are easy to connect. The model itself should update itself depending upon what data you feed it and shouldn&rsquo;t be limited as such. By arbitrarily limiting it you&rsquo;re really just kicking yourself later on down the road.</p>

<p>So, how can we avoid screwing up, and start developing elegant repeatable code? Let&rsquo;s go through a couple options.</p>

<ul>
<li>Folder structure and file naming</li>
<li>Version Control</li>
<li>Smarter development of objects and functions</li>
<li>Modules and packages</li>
<li>Tests</li>
</ul>


<h2>Folder Structure and File Naming</h2>

<p>Folder structure, or directory layout, seems like a strange thing to be placing upon a list of developing elegant code. Same with file naming. So what does this have to do with research and developing code? Quite simply a lot. Let&rsquo;s talk about the initial folder layout I use a simple three tier approach as follows.</p>

<p>Note, that here the data is for trivial examples. If you&rsquo;re using anything more complex then I highly recommend you start researching into Databases and whether your data is suitable for them. However, one caveat is that introducing a Database layer may add significant overhead and if you are unskilled this may be beyond you. Nonetheless, give it a try, see if you like it. As a general rule of thumb think about how much information you are needing to store. 10 MB, you may be okay with a file. 100 MB, pushing it, possibly okay if you&rsquo;re using a library like pandas and vectorised calculations. 1000 MB, Databases start becoming your friend very very quickly. Additionally, you should ask yourself whether other people will also need access to the data sources.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>data
</span><span class='line'>  - set_one
</span><span class='line'>  - set_two
</span><span class='line'>scripts
</span><span class='line'>  - experiment_one
</span><span class='line'>  - experiment_two
</span><span class='line'>modules
</span><span class='line'>  - module_one
</span><span class='line'>  - module_two</span></code></pre></td></tr></table></div></figure>


<p>Now, what I&rsquo;ve done is I&rsquo;ve completed separated the three key aspects of my work. All of my data is contained within its own folder. I don&rsquo;t touch it and I certainly don&rsquo;t change any of the files within once they&rsquo;ve been modified. What this ensures is that if I chose to repeat something I can be sure that my dataset hasn&rsquo;t changed, and that assuming that the code has changed my program and code should just <em>work</em>.</p>

<p>Secondly, I&rsquo;ve separated out my scripts and modules. Here we should define what each is. A module is something you&rsquo;ve developed which is testable and method independent. It may be a package you&rsquo;ve got off <a href="github.com">github</a> or something you&rsquo;ve developed yourself, such as a useful package of <a href="github.com/NigelCleland/pdtools">tools</a>. Now, your scripts on the other hand are the nitty gritty of what you do. You can still write these in a terrible fashion however at least the tools you use, and the data you run it on should be easily separable.</p>

<h2>Version Control</h2>

<p>What is Version Control and why, as a researcher, do I care? Ever worked with other people and what ends up getting passed around is a ton of files with names such as <code>file_name_person_number_44_date_37_final_copy_3.ext</code>. If yes, and if this made you absolutely hate life and become seriously concerned about the future well being of the human race then version control is for you!
Now, I recommend using what people are comfortable with, however if you&rsquo;re new to it then my recommendation is to pick up git.</p>

<p>Git is a decentralised version control system which makes merging together branches etc easy. Don&rsquo;t know what any of that means? Then pick up a copy of the progit book from github and get reading. I&rsquo;m not going to go through all of the nitty gritty here, just to say that you should be using it and if you&rsquo;re not then file name hell may be for you! Importantly, version control lets you do as the name suggests and manage different versions of something in a sane easy to implement manner. What is great about it is if you use a plain text based document system, such as LaTeX then you can also manage your documents with it. This makes storing different versions simple (e.g. define a branch as 0.1.0) and you&rsquo;ll always be able to return to that branch for prior iterations.</p>

<h2>Smarter development of objects and functions</h2>

<p>Whenever you need to hard code something in to your scripts you should ask yourself. Do I really need to be doing this? Is there a better way? Can I write this in such a way that I will understand it a week from now, a month from now? Code should be written so that it is easy for you to understand, not the machine. If at a later point you need something to be faster then by all means start optimising things (e.g. move towards C). However, initially write it so that you can understand it. Only rewrite the truly performance critical parts.</p>

<p>Here things which help include, keyword arguments instead of hard coded parameters. Comments, docstrings, shorter functions. Resist the urge to develop so called &ldquo;God&rdquo; functions or classes that do everything. Instead, separate these (where sensible) into smaller reusable functions or methods. Obviously this is context specific and I&rsquo;m not going to give too many specifics.</p>

<p>Just imagine future you is standing behind you with a shotgun and will pull the trigger if he doesn&rsquo;t understand what, or why, you are doing something in particular which is undocumented. The other key element here is to avoid, where possible, scope creep.</p>

<p>Don&rsquo;t just randomly and haphazardly add new methods, or functions to a script and make it do something completely unexpected because it was easier at the time. Separate out the components and then join them together in an intelligent fashion.</p>

<h2>Modules and packages</h2>

<p>Modules and packages are simply reusable code. They&rsquo;re broadly use case independent and are therefore fantastic for saving time. There are hundreds of packages out there which will simplify your life and make you more productive. My advice is to use them.</p>

<p>My second piece of advice is to take those functions which you use again and again and create your own custom packages. You don&rsquo;t have to release this to the general public but a toolbox which makes your life far far easier is not something to be dismissed. The code you write which goes into your module should be the best code you&rsquo;ve written. You&rsquo;re going to be using it hundreds of times and you want to know exactly what it will do in all situations.</p>

<h2>Tests</h2>

<p>Finally we come to the worst aspect of coding from my personal point of view. I know some people love writing tests, and enjoy test driven methodology however I see a key difference here. A lot of the people who enjoy test driven coding are writing software. In research we&rsquo;re often developing a number of small scripts which we use to generate results. Quite simply we don&rsquo;t have the same sense of scale, or requirements, as other programmers.</p>

<p>Therefore, where are tests useful? Tests are most useful in your modules and packages, and less useful in your custom scripts. My general rule of thumb is as follows, if I&rsquo;m going to use this in multiple places and multiple situations then I am going to want a test for each of those places and situations. If I don&rsquo;t do this then I may make a modification for one particular use case forgetting that you&rsquo;re depending upon the previous functionality for a separate usecase. A test, if implemented and properly, would catch this behaviour and you can hopefully develop smarter.</p>

<p>However, the key element here is that you&rsquo;re reusing code. If you are using it once, in a very specific situation then the code itself almost becomes a test. If it works, then the function is correct. If it doesn&rsquo;t work, the function is wrong. As there is only one use case is there much value in developing a test which repeats our use case?</p>

<h2>Conclusions</h2>

<p>In this post I&rsquo;ve argued, and laid out a few examples, of why and how you should be writing more repeatable code as a researcher. The list is by no means complete and is still a work in progress. I am after all still learning how to write better code, something which will continue as long as I am writing code.</p>

<p>Feel free to ask any questions in the comments.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Tutorial Series: Merging Series with Pandas]]></title>
    <link href="http://NigelCleland.github.io/blog/2013/05/18/tutorial-series-merging-series-with-pandas/"/>
    <updated>2013-05-18T19:03:00+12:00</updated>
    <id>http://NigelCleland.github.io/blog/2013/05/18/tutorial-series-merging-series-with-pandas</id>
    <content type="html"><![CDATA[<p>This post will cover some quick usage surrounding merging a Series and a DataFrame or merging two Series together. This is functionality which I&rsquo;ve often felt is lacking and is boiler plate I&rsquo;ve had to write a number of times. I&rsquo;ve added the functionality to my new repo <a href="github.com/NigelCleland/pdtools">pdtools</a> and should hopefully simplify life for other people.</p>

<p>This post will be a simple explanation as to how it works as well as a brief explanation. Broadly, as some of my work I had to work with extremely large datasets, tens of millions of rows, dozens of columns the full works. I had to merge aspects of these datasets together, often from disparate data sources. one element which was particularly frustrating for me was having large numbers of duplicate columns, and irrelevant information when all I wanted was a single series.</p>

<!-- more -->


<p>So, how do we get around this issue. First a brief overview of merging DataFrames together with Pandas. Of course the pandas documentation covers this in far more depth but in general the code we are interested in is as follows (for index merging)</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
</span><span class='line'><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
</span><span class='line'>
</span><span class='line'><span class="c"># Create DataFrames</span>
</span><span class='line'><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">((</span><span class="mi">10</span><span class="p">,</span><span class="mi">4</span><span class="p">)),</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s">&quot;A&quot;</span><span class="p">,</span><span class="s">&quot;B&quot;</span><span class="p">,</span><span class="s">&quot;C&quot;</span><span class="p">,</span><span class="s">&quot;D&quot;</span><span class="p">])</span>
</span><span class='line'><span class="n">df1</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s">&quot;A&quot;</span><span class="p">,</span> <span class="s">&quot;B&quot;</span><span class="p">]]</span>
</span><span class='line'><span class="n">df2</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s">&quot;C&quot;</span><span class="p">,</span> <span class="s">&quot;D&quot;</span><span class="p">]]</span>
</span><span class='line'>
</span><span class='line'><span class="c"># Merging Method One</span>
</span><span class='line'>
</span><span class='line'><span class="n">df3</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">df1</span><span class="p">,</span> <span class="n">df2</span><span class="p">,</span> <span class="n">how</span><span class="o">=</span><span class="s">&#39;inner&#39;</span><span class="p">,</span> <span class="n">left_index</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">right_index</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</span><span class='line'><span class="n">df3</span> <span class="o">==</span> <span class="n">df</span> <span class="c"># Should return True</span>
</span><span class='line'>
</span><span class='line'><span class="c"># Method Two</span>
</span><span class='line'>
</span><span class='line'><span class="n">df4</span> <span class="o">=</span> <span class="n">df1</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">df2</span><span class="p">,</span> <span class="n">left_index</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">right_index</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</span><span class='line'><span class="n">df4</span> <span class="o">==</span> <span class="n">df</span> <span class="c"># Should return True</span>
</span><span class='line'>
</span><span class='line'><span class="c"># Method Three</span>
</span><span class='line'><span class="n">df5</span> <span class="o">=</span> <span class="n">df2</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">df1</span><span class="p">,</span> <span class="n">left_index</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">right_index</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</span><span class='line'><span class="n">df5</span> <span class="o">==</span> <span class="n">df</span> <span class="c"># Will return False as columns are different</span>
</span><span class='line'><span class="n">df5</span> <span class="o">=</span> <span class="n">df5</span><span class="p">[[</span><span class="s">&quot;A&quot;</span><span class="p">,</span> <span class="s">&quot;B&quot;</span><span class="p">,</span> <span class="s">&quot;C&quot;</span><span class="p">,</span> <span class="s">&quot;D&quot;</span><span class="p">]]</span> <span class="c"># Reorder the columns</span>
</span><span class='line'><span class="n">df5</span> <span class="o">==</span> <span class="n">df</span> <span class="c"># Should return True</span>
</span></code></pre></td></tr></table></div></figure>


<p>Broadly, we can either merge two DataFrames using the general pandas merge method, or the specific DataFrame method. Now what if we want to merge a series into a DataFrame, for ecxample.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="n">s1</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">&quot;C&quot;</span><span class="p">]</span>
</span><span class='line'><span class="n">s2</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">&quot;D&quot;</span><span class="p">]</span>
</span><span class='line'>
</span><span class='line'><span class="c"># Pseudo code</span>
</span><span class='line'><span class="n">df6</span> <span class="o">=</span> <span class="n">df1</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">s1</span><span class="p">)</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">s2</span><span class="p">)</span> <span class="c"># Fails miserably</span>
</span></code></pre></td></tr></table></div></figure>


<p>Broadly, pandas just does not like doing this. However, we can get around this by creating a single column DataFrame from the Series and merging that as follows.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="c"># As a single statement, note this is not the best way to do this.</span>
</span><span class='line'><span class="c"># I&#39;m also taking advantage of the fact that the series has a name which</span>
</span><span class='line'><span class="c"># Will be passed as the new column name.</span>
</span><span class='line'><span class="n">df6</span> <span class="o">=</span> <span class="n">df1</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="n">s1</span><span class="o">.</span><span class="n">name</span> <span class="p">:</span> <span class="n">s1</span><span class="p">}),</span> <span class="n">left_index</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">right_index</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="n">s2</span><span class="o">.</span><span class="n">name</span> <span class="p">:</span> <span class="n">s2</span><span class="p">}),</span> <span class="n">left_index</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">right_index</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>Wow, that is ugly. Wouldn&rsquo;t it be simpler if we could just merge the two together. Now, what we can do is create a bit of a wrapper and syntactic sugar around our ugly code above. Let&rsquo;s wrap it in a function to begin with.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="k">def</span> <span class="nf">merge_dataframe_series</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="o">**</span><span class="n">kwds</span><span class="p">):</span>
</span><span class='line'>  <span class="k">return</span> <span class="n">df</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="n">s</span><span class="o">.</span><span class="n">name</span><span class="p">:</span> <span class="n">s</span><span class="p">}),</span> <span class="o">**</span><span class="n">kwds</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'><span class="n">df7a</span> <span class="o">=</span> <span class="n">merge_dataframe_series</span><span class="p">(</span><span class="n">df1</span><span class="p">,</span> <span class="n">s1</span><span class="p">,</span> <span class="n">left_index</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">right_index</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</span><span class='line'><span class="n">df7</span> <span class="o">=</span> <span class="n">merge_dataframe_series</span><span class="p">(</span><span class="n">df7a</span><span class="p">,</span> <span class="n">s2</span><span class="p">,</span> <span class="n">left_index</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">right_index</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="n">df7</span> <span class="o">==</span> <span class="n">df</span> <span class="c"># Returns True</span>
</span></code></pre></td></tr></table></div></figure>


<p>Hmmm, slightly, better but still pretty sub par over all. Lets cover the things which are wrong with the first attempt.</p>

<ol>
<li>Pretty unwieldy syntax, have to call it with a DataFrame and Series.</li>
<li>Still need a lot of key word arguments to specify how the merge will occur.</li>
<li>The name is very long, want it much shorter and sweeter.</li>
<li>Ideally we want to be able to call this directly from a DataFrame.</li>
</ol>


<p>So, let&rsquo;s try again.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="k">def</span> <span class="nf">merge_series</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">series</span><span class="p">,</span> <span class="o">**</span><span class="n">kwds</span><span class="p">):</span>
</span><span class='line'>  <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="n">series</span><span class="o">.</span><span class="n">name</span><span class="p">:</span> <span class="n">series</span><span class="p">}),</span> <span class="n">right_index</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwds</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">.</span><span class="n">merge_series</span> <span class="o">=</span> <span class="n">merge_series</span>
</span><span class='line'>
</span><span class='line'><span class="n">df8</span> <span class="o">=</span> <span class="n">df1</span><span class="o">.</span><span class="n">merge_series</span><span class="p">(</span><span class="n">s1</span><span class="p">,</span> <span class="n">left_index</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span><span class="o">.</span><span class="n">merge_series</span><span class="p">(</span><span class="n">s2</span><span class="p">,</span> <span class="n">left_index</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="n">df8</span> <span class="o">==</span> <span class="n">df</span> <span class="c"># Should be True</span>
</span></code></pre></td></tr></table></div></figure>


<p>Now that is much better. The usage is much simpler, we don&rsquo;t need to specify what DataFrame since it is now a method of the DataFrame class. Since we&rsquo;re always going to be using the index of the Series we can automatically incorporate the <code>right_index=True</code> directly into the function. We&rsquo;re still using the **kwds to pass what argument we want for the merge function. Thus we don&rsquo;t need to use the index on the DataFrame, we could use a column using <code>left_on="column"</code> as well.</p>

<p>Let&rsquo;s also do the same for a series</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="c"># Use series_merge instead of merge_series to avoid name space error.</span>
</span><span class='line'><span class="c"># We&#39;ll map it to merge_series to maintain the consistent api usage though.</span>
</span><span class='line'><span class="k">def</span> <span class="nf">series_merge</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="o">**</span><span class="n">kwds</span><span class="p">):</span>
</span><span class='line'>  <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">:</span> <span class="bp">self</span><span class="p">})</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="n">other</span><span class="o">.</span><span class="n">name</span> <span class="p">:</span> <span class="n">other</span><span class="p">}),</span> <span class="n">left_index</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">right_index</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="o">.</span><span class="n">merge_series</span> <span class="o">=</span> <span class="n">series_merge</span>
</span><span class='line'>
</span><span class='line'><span class="n">df9</span> <span class="o">=</span> <span class="n">s1</span><span class="o">.</span><span class="n">merge_series</span><span class="p">(</span><span class="n">s2</span><span class="p">)</span>
</span><span class='line'><span class="n">df10</span> <span class="o">=</span> <span class="n">df1</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">df9</span><span class="p">,</span> <span class="n">left_index</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">right_index</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</span><span class='line'><span class="n">df10</span> <span class="o">==</span> <span class="n">df</span> <span class="c"># Should be True</span>
</span></code></pre></td></tr></table></div></figure>


<p>Now, since we can only merge series based upon their indices. I&rsquo;m happy to be corrected on this but it is difficult to think of a different use case we can automatically assign the <code>left_index=True</code> and <code>right_index=True</code> key word arguments to simplify it.</p>

<p>Now, what we&rsquo;ve accomplished in this blog post is a couple quick helper functions to make merging Series together, and into DataFrames much much simpler. These are automatically incorporated into the pdtools package. To apply this functionality you can download the package and incorporate it.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
</span><span class='line'><span class="kn">import</span> <span class="nn">pdtools.merging</span> <span class="c"># Just import the two merge functions</span>
</span><span class='line'>
</span><span class='line'><span class="c"># Or</span>
</span><span class='line'><span class="kn">import</span> <span class="nn">pdtools</span> <span class="c"># Will import masks as well.</span>
</span></code></pre></td></tr></table></div></figure>


<p>If using the general purpose pdtools import the masks functionality will also be added to the pandas classes. A brief overview of this functionality can be found <a href="http://nigelcleland.github.io/blog/2013/05/12/selecting-data-with-pandas/">here</a>.</p>

<p>Thoughts/Questions/etc, open an issue on <a href="https://github.com/nigelcleland/pdtools/issues">github</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Tutorial Series: Using pandas groupby to simplify your life]]></title>
    <link href="http://NigelCleland.github.io/blog/2013/05/16/tutorial-series-using-pandas-groupby-to-simplify-your-life/"/>
    <updated>2013-05-16T10:40:00+12:00</updated>
    <id>http://NigelCleland.github.io/blog/2013/05/16/tutorial-series-using-pandas-groupby-to-simplify-your-life</id>
    <content type="html"><![CDATA[<p>This is the second instalment in a brief series on using the pandas library for data analysis. The general aim of this series to to highlight some of the cool functionality which is in pandas. None of this is revolutionary, however Wes McKinney and the other contributors have made exceptional contributions to the speed and ease of which it is completed.</p>

<p>In this post I&rsquo;m going to over the groupby function. Highlight a couple of the interesting things which you can do with it and generally show how much simpler pandas makes it to accomplish data analysis. I&rsquo;m going to be using a real data set, hydrology data from the last 80 odd years for the New Zealand electricity grid, this dataset has approximately 30,000 data points (1 per day) and is therefore a good size for this work. This post will cover a brief example of using groupby for time series and won&rsquo;t go through any of the more complex functionality and usage which can be developed when working with full DataFrames.</p>

<!-- more -->


<p>Right to begin we need to load our data, I&rsquo;m going to use a custom module which makes this a bit easier called <a href="http://github.com/NigelCleland/nzem">nzem</a>. The nzem library is my own personal library which simplifies some of the initial data analysis I use most frequently. For example, the following will load hydrology data and automatically parse the relatively disgusting date format which the csv file has. Note, that the nzem module automatically loads and initlises the <a href="http://github.com/NigelCleland/masks">masks</a> library which I discussed in my last post.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="c"># Load modules</span>
</span><span class='line'><span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
</span><span class='line'><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
</span><span class='line'><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>
</span><span class='line'><span class="kn">import</span> <span class="nn">nzem</span>
</span><span class='line'>
</span><span class='line'><span class="c"># Load the data, niwa_date is a specific format not recognised by the dateutil.parser utility</span>
</span><span class='line'><span class="n">hydro_data</span> <span class="o">=</span> <span class="n">nzem</span><span class="o">.</span><span class="n">load_csvfile</span><span class="p">(</span><span class="s">&#39;hydro_data/Hydro_Lake_Data.csv&#39;</span><span class="p">,</span> <span class="n">niwa_date</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="c"># Get a single column, daily_level will then be a series</span>
</span><span class='line'><span class="n">daily_level</span> <span class="o">=</span> <span class="n">hydro_data</span><span class="p">[</span><span class="s">&quot;Daily Stored&quot;</span><span class="p">]</span>
</span><span class='line'>
</span><span class='line'><span class="c"># Confirmation that we are working with a time series</span>
</span><span class='line'><span class="nb">type</span><span class="p">(</span><span class="n">daily_level</span><span class="p">)</span> <span class="c"># pandas.core.series.Series</span>
</span><span class='line'><span class="nb">type</span><span class="p">(</span><span class="n">daily_level</span><span class="o">.</span><span class="n">index</span><span class="p">)</span> <span class="c"># pandas.tseries.index.DatetimeIndex</span>
</span></code></pre></td></tr></table></div></figure>


<p>Now, we have a single series which contains the daily storage level of the entire countries hydro lakes (in GWh).</p>

<p>Now, on to using the group by functionality. The pandas <a href="http://pandas.pydata.org/pandas-docs/stable/groupby.html">groupby</a> library has two primary uses. Aggregations and Transformations. An Aggregation will return a new series with indices set by the groupby keys.
A Transformation will return the original series transformed according to the predefined function.</p>

<p>This is best demonstrated by example</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="c"># Aggregation</span>
</span><span class='line'><span class="c"># Group by the day of year, take the mean of these points</span>
</span><span class='line'><span class="n">doy</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">dayofyear</span>
</span><span class='line'><span class="n">doy_mean</span> <span class="o">=</span> <span class="n">daily_level</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">doy</span><span class="p">)</span><span class="o">.</span><span class="n">aggregate</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">)</span> <span class="c"># Note you don&#39;t need to use the () at the end of np.mean.</span>
</span><span class='line'>
</span><span class='line'><span class="nb">len</span><span class="p">(</span><span class="n">doy_mean</span><span class="p">)</span> <span class="c"># 366, one for each day</span>
</span><span class='line'>
</span><span class='line'><span class="c"># Transformation</span>
</span><span class='line'><span class="c"># Group by the day of year, but subtract the mean from each point</span>
</span><span class='line'>
</span><span class='line'><span class="n">relative_mean</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span class='line'><span class="n">doy_rel_mean</span> <span class="o">=</span> <span class="n">daily_level</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">doy</span><span class="p">)</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">relative_mean</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="nb">len</span><span class="p">(</span><span class="n">doy_rel_mean</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">daily_level</span><span class="p">)</span> <span class="c"># returns True</span>
</span></code></pre></td></tr></table></div></figure>


<p>Now, we need to cover where we use each one. The aggregations are useful when what we are interested in is the summary statistic, and we do not intend to remerge it with our dataframe. For example, if we wanted to remerge it we would have to go through a bunch of steps which would be quite painful. The transform function on the other hand should be used when you want a data point equivalent to each of the original series/dataframe.</p>

<p>For example, in the above example the transform example can be used to create a repeating series which we then apply against our raw data. A visual explanation as to why this is beneficial may be most appropriate.
I&rsquo;m not going to attempt to make this figure extremely pretty, that is for a later post which will cover beautifying matplotlib somewhat. I am chaining methods here which if you are not used to pandas may be slightly confusing. The explanation is that</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="c"># Helper functions to reduce line length</span>
</span><span class='line'><span class="n">per10</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">q</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</span><span class='line'><span class="n">rel_per10</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span> <span class="o">-</span> <span class="n">per10</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="c"># Create our subplots, share the y axis to make comparison more intuitive</span>
</span><span class='line'><span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span><span class="mi">9</span><span class="p">),</span> <span class="n">sharey</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="c"># Plot from 2012 only to avoid too much visual clutter.</span>
</span><span class='line'><span class="c"># Raw Data</span>
</span><span class='line'><span class="n">daily_level</span><span class="o">.</span><span class="n">ix</span><span class="p">[</span><span class="s">&quot;2012&quot;</span><span class="p">:]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</span><span class='line'>
</span><span class='line'><span class="c"># Transformation to be applied</span>
</span><span class='line'><span class="n">daily_level</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">doy</span><span class="p">)</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">per10</span><span class="p">)</span><span class="o">.</span><span class="n">ix</span><span class="p">[</span><span class="s">&quot;2012&quot;</span><span class="p">:]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</span><span class='line'>
</span><span class='line'><span class="c"># Final Result</span>
</span><span class='line'><span class="n">daily_level</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">doy</span><span class="p">)</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">rel_per10</span><span class="p">)</span><span class="o">.</span><span class="n">ix</span><span class="p">[</span><span class="s">&quot;2012&quot;</span><span class="p">:]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
</span><span class='line'>
</span><span class='line'><span class="c"># Labels</span>
</span><span class='line'><span class="n">titles</span> <span class="o">=</span> <span class="p">[</span><span class="s">&quot;Raw hydrology data&quot;</span><span class="p">,</span> <span class="s">&quot;Bottom Decile&quot;</span><span class="p">,</span> <span class="s">&quot;Transformed Data&quot;</span><span class="p">]</span>
</span><span class='line'><span class="k">for</span> <span class="n">ax</span><span class="p">,</span> <span class="n">title</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">axes</span><span class="p">,</span> <span class="n">titles</span><span class="p">):</span>
</span><span class='line'>  <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s">&quot;Quantity of Hydro Storage [GWh]&quot;</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="n">fig</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s">&quot;hydro_data_over_time.png&quot;</span><span class="p">,</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">150</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>


<p><img src="http://NigelCleland.github.io/images/may2013/hydro_data_over_time.png"></p>

<p>Right, an explanation. What we have done is create three plots which gives the reader a fairly decent overview as to the hydrology situation from 2012 onwards. From this figure we get an appreciation of the raw situation as seen on a daily basis. In the second plot we can then visually compare this to the bottom decile of what has occurred for the past 80 years. Finally, in the final plot we compare the two sets of data which highlights the low hydro storage experienced during the Autumn and Winter of 2012. It also adequately shows the large series of inflows which occurred over the 2012-2013 new year periods. Finally, the tail end of the figure shows that hydrology levels have again deteriorated from the large burst of inflows.</p>

<p>Not too bad for a few simple lines of code. In total, to produce the image required 14 individual lines excluding the module import.</p>

<p>Hopefully this post has given you a bit more of a detailed explanation as to using the groupby functionality, especially with time series. I&rsquo;ll attempt to extend upon this in the coming days as time and motivation permits.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Tutorial Series: Selecting Data with Pandas]]></title>
    <link href="http://NigelCleland.github.io/blog/2013/05/12/selecting-data-with-pandas/"/>
    <updated>2013-05-12T13:12:00+12:00</updated>
    <id>http://NigelCleland.github.io/blog/2013/05/12/selecting-data-with-pandas</id>
    <content type="html"><![CDATA[<p>As part of my job I need to do a large amount of sample analysis, and visualisation of small subsets of data. This requires a large quantity of iteration, trial and error and repetitive coding. Something we all wish we could avoid, yet sometimes can&rsquo;t. To give a practical example, I often need to work with half hourly data, for a wide range of individual metrics which may have similarities. What I need to do, is isolate this data in various ways.</p>

<p>EDIT: The original post used a library called masks. I&rsquo;ve decided to merge this into a larger directory to be called <a href="http://github.com/NigelCleland/pdtools">pdtools</a>. This directory will contain more helper functions and methods, not just masks.</p>

<!-- more -->


<p>Now, here we introduce pandas. Pandas is an analysis library for Python built on top of numpy for fast merges, joins and analysis. It is an essential part of my day to day work and if you have to work with any decent amount of data I highly recommend using it. However, there is one slight issue I&rsquo;ve had with it. Selecting small subsets of data in a simple fashion. To give an example, in python, to iterate we can use:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">container</span><span class="p">:</span>
</span><span class='line'>    <span class="k">if</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">subset</span><span class="p">:</span>
</span><span class='line'>          <span class="k">print</span> <span class="n">item</span>
</span></code></pre></td></tr></table></div></figure>


<p>Here the key is that we&rsquo;re looking at the entire container, and then assessing whether our item fits that subset. However, in pandas it isn&rsquo;t so easy.
In Pandas, to select a subset of the data we create an array of booleans and then apply this to the dataframe as follows:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
</span><span class='line'><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
</span><span class='line'>
</span><span class='line'><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s">&quot;A&quot;</span><span class="p">,</span> <span class="s">&quot;B&quot;</span><span class="p">,</span> <span class="s">&quot;C&quot;</span><span class="p">,</span> <span class="s">&quot;D&quot;</span><span class="p">])</span>
</span><span class='line'>
</span><span class='line'><span class="n">subset</span> <span class="o">=</span> <span class="n">df</span><span class="p">[(</span><span class="n">df</span><span class="p">[</span><span class="s">&quot;A&quot;</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="mf">0.5</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">&quot;B&quot;</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mf">0.2</span><span class="p">)]</span>
</span></code></pre></td></tr></table></div></figure>


<p>In this example, we are selecting a subset of our data which satisfies the condition of column A being less than or equal to 0.5 and column B greater than or equal to 0.2. (Note, the brackets around each statement are required.</p>

<p>However, this syntax, while clear for simple examples does start to break down at higher orders. For example, let&rsquo;s say we had qualitative values in our data frame and we want to select a small subset of them. We cannot use the in operator, or a multiple equal operator. Instead, we need to use the or operator.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="c"># Note this won&#39;t work:</span>
</span><span class='line'><span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s">&quot;A&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="p">(</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">)]</span>
</span><span class='line'>
</span><span class='line'><span class="c"># Require the following:</span>
</span><span class='line'><span class="n">df</span><span class="p">[(</span><span class="n">df</span><span class="p">[</span><span class="s">&quot;A&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="mf">0.3</span><span class="p">)</span> <span class="o">|</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">&quot;A&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="mf">0.2</span><span class="p">)</span> <span class="o">|</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">&quot;A&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="mf">0.7</span><span class="p">)]</span>
</span></code></pre></td></tr></table></div></figure>


<p>As you can see the amount of duplicate code requires continues to increase linearly with each additional item we wish to check. Is there a better way?
Turns out, maybe.</p>

<p>What I have done is develop a range of common masks and place them in a single <a href="https://github.com/NigelCleland/masks">repository</a> or it may be downloaded using pip</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="n">pip</span> <span class="n">install</span> <span class="n">masks</span>
</span></code></pre></td></tr></table></div></figure>


<p>To use it, you simply import the masks module after importing pandas and it will apply a number of additional methods to the Series and DataFrame classes in the pandas module. I&rsquo;ve attempted to avoid all known api clashes through the addition of _masks at the end of each function, which should also make the meaning clearer. Using this module our multiple selection example becomes much simpler</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
</span><span class='line'><span class="kn">import</span> <span class="nn">masks</span>
</span><span class='line'><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
</span><span class='line'>
</span><span class='line'><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">30</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s">&quot;A&quot;</span><span class="p">,</span> <span class="s">&quot;B&quot;</span><span class="p">,</span> <span class="s">&quot;C&quot;</span><span class="p">])</span>
</span><span class='line'>
</span><span class='line'><span class="c"># Use the in_eqmask this mask will return all values which meet the conditions</span>
</span><span class='line'><span class="c"># the eqmask instead of just mask is to specify that equality conditions are</span>
</span><span class='line'><span class="c"># being introduced</span>
</span><span class='line'>
</span><span class='line'><span class="n">df</span><span class="o">.</span><span class="n">in_eqmask</span><span class="p">(</span><span class="s">&quot;A&quot;</span><span class="p">,</span> <span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">24</span><span class="p">))</span>
</span><span class='line'>
</span><span class='line'><span class="c"># Or another simple use case which has frustrated me endlessly in pandas is</span>
</span><span class='line'><span class="c"># returning all rows which satisfy a between type condition.</span>
</span><span class='line'>
</span><span class='line'><span class="n">df</span><span class="p">[(</span><span class="n">df</span><span class="p">[</span><span class="s">&quot;A&quot;</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mf">0.5</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">&quot;A&quot;</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="mf">0.7</span><span class="p">)]</span>
</span><span class='line'><span class="n">df</span><span class="o">.</span><span class="n">bet_mask</span><span class="p">(</span><span class="s">&quot;A&quot;</span><span class="p">,</span> <span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">))</span>
</span></code></pre></td></tr></table></div></figure>


<p>Which is much much simpler no?</p>

<p>An additional benefit of this is that we are able to chain methods together in order to create the desired subsets. For example.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="n">df</span><span class="o">.</span><span class="n">ge_mask</span><span class="p">(</span><span class="s">&quot;A&quot;</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">le_mask</span><span class="p">(</span><span class="s">&quot;C&quot;</span><span class="p">,</span> <span class="mi">15</span><span class="p">)</span><span class="o">.</span><span class="n">ne_mask</span><span class="p">(</span><span class="s">&quot;B&quot;</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>We just applied three different refinements to get all rows of the dataframe where A is greater than 5, C less than 15 and B not equal to 10.</p>

<p>There are a few more complex functions in the module, such as selecting the top, bottom or middle x% of a particular column or columns e.g.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="c"># Take the rows which satisfy the top 25% of column A, then take the bottom 10% of column B</span>
</span><span class='line'><span class="c"># from this subset.</span>
</span><span class='line'><span class="n">df</span><span class="o">.</span><span class="n">top_mask</span><span class="p">(</span><span class="s">&quot;A&quot;</span><span class="p">,</span> <span class="mi">25</span><span class="p">)</span><span class="o">.</span><span class="n">bot_mask</span><span class="p">(</span><span class="s">&quot;B&quot;</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>masks is still a work in progress, however it is usable as is for prototyping and data exploration. There are a number of additional features which are still needed at this stage. There repo is <a href="https://github.com/NigelCleland/masks">here</a> and all contributions/comments are welcome. I&rsquo;m not sure this is the best way to add this functionality, however it has been useful for me in the past and thus I&rsquo;m putting it out there incase anyone else finds it useful.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Introduction and blog content]]></title>
    <link href="http://NigelCleland.github.io/blog/2013/05/09/introduction-and-blog-content/"/>
    <updated>2013-05-09T12:43:00+12:00</updated>
    <id>http://NigelCleland.github.io/blog/2013/05/09/introduction-and-blog-content</id>
    <content type="html"><![CDATA[<p>So, first a brief introduction.
My name is Nigel and I am currently a Ph.D student at the University of Auckland, New Zealand.
My current research is on market based systems for procuring security (reserve) in electricity markets.
In particular, I do a substantial amount of data analysis attempting to assess the consequences and frequency of constrained situations.
I&rsquo;m currently ~1.5 years into this.</p>

<!-- more -->


<p>This blog is intended to serve as predominately writing practice, as well as thoughts on technical and esoteric matters.
I try to use open source software as much as possible in my day to day work with Python, LaTeX and Ubuntu being the main elements.
I would like to contribute more to open source in the future, however I&rsquo;m not entirely sure on the best way to accomplish this.
Hopefully, some blog posts on semi technical matters may provide a stepping stone for this.
I typically use Python for data analysis, especially the incredibly useful pandas and matplotlib libraries.</p>

<p>Outside of this, I love reading, tinkering with and building assorted trinkets/toys and weight lifting.
I plan on using this blog to post on a range of subjects which I have found both interesting and useful over the years.
As such, content may vary greatly.
In particular, I&rsquo;m trying to read a large number of new books with the broadly ambitious aim to read at least one on average every week.
This ambitious tends to often be thwarted by running out of new books to read.
I typically read a lot of print books, not because I am a luddite as I have previously bought, and read, a lot of kindle books.
But mainly because of the concept of ownership and what happens to such books if Amazon or some other company were to change its terms of service.</p>

<p>I am a bit of an information junkie, which I&rsquo;m trying to control as it does tend to consume a lot of my time.
Short form information, which tends to skirt a subject and not really cover it in depth is not exactly a great source of information.
As such, I&rsquo;m attempting to read more literature, long form articles and in depth coverage of topics.
In addition, contributing to these by writing about them is something I want to initiate and this is a good first step.</p>

<p>Finally, I have no set schedule for updating this blog although I will attempt to do so as frequently as my interest permits.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Setting up Octopress with Ubuntu]]></title>
    <link href="http://NigelCleland.github.io/blog/2013/05/08/setting-up-octopress/"/>
    <updated>2013-05-08T19:41:00+12:00</updated>
    <id>http://NigelCleland.github.io/blog/2013/05/08/setting-up-octopress</id>
    <content type="html"><![CDATA[<p>Right, so this post will serve as a general overview as to a couple of the difficulties I had when setting up Octopress and Ruby.
I mainly use Python for my day to day analysis work and as such have little experience with Ruby.
I used rbenv for my installation and a couple issues arose which were a bit of a pain to sort out as googling appeared to let me down here.</p>

<!-- more -->


<p>So a couple things. If you are using Ubuntu then you need to use .profile instead of .bash_profile.
If done right the bottom two lines of the following should be.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>cat ~/.profile
</span><span class='line'>
</span><span class='line'>export PATH="$HOME/.rbenv/bin:$PATH
</span><span class='line'>eval "$(rbenv init -)"</span></code></pre></td></tr></table></div></figure>


<p></p>

<p>Another issue which may arise is the difference between the system, and rbenv ruby installation.
The commands you are looking for here are as follows.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>rbenv versions # Will list the installed versions of rbenv
</span><span class='line'>rbenv local &lt;build&gt; # Will set a local version of ruby for the specific folder
</span><span class='line'>rbenv global &lt;build&gt; # Specify the global build of ruby to use.
</span><span class='line'>ruby --version # List the current version of ruby</span></code></pre></td></tr></table></div></figure>


<p>I recommend playing around with each of these commands until you&rsquo;re comfortable switching between different versions of ruby.
In my initial installations I was having a lot of difficulty with different versions of ruby in different locations.
Generally, just a major annoyance to say the least.</p>

<p>Once these two issues were sorted out installation was pretty simple overall.
Hopefully if anyone else is having similar difficulties this post may point them in the right direction.</p>

<p>I&rsquo;ll update this post if needed or if I remember something new.</p>
]]></content>
  </entry>
  
</feed>
