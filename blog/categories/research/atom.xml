<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: research | My Escape]]></title>
  <link href="http://NigelCleland.github.io/blog/categories/research/atom.xml" rel="self"/>
  <link href="http://NigelCleland.github.io/"/>
  <updated>2013-10-19T09:50:23+13:00</updated>
  <id>http://NigelCleland.github.io/</id>
  <author>
    <name><![CDATA[Nigel Cleland]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[What I'm currently working on]]></title>
    <link href="http://NigelCleland.github.io/blog/2013/05/27/what-im-currently-working-on/"/>
    <updated>2013-05-27T19:52:00+12:00</updated>
    <id>http://NigelCleland.github.io/blog/2013/05/27/what-im-currently-working-on</id>
    <content type="html"><![CDATA[<p>Haven&rsquo;t been able to write as much as I would have liked to over the past week. Been a bit tied up with other things going on. Thus, I thought I&rsquo;d take this opportunity to run through each of the various projects and research lines I&rsquo;m going down at the moment. Hopefully this should be a bit of an overview as to what I actually do.</p>

<p>Broadly I&rsquo;ll divide my projects into three categories, write up stage, in progress stage and backburner stage. A project in write up stage is currently undergoing final revisions before submission to journals/conferences etc. Ones in the in progress stage are what I&rsquo;m currently actively developing. This includes a lot of experimentation and prototyping to help consolidate my thoughts. Finally, the ones on the backburner stage are those which I&rsquo;m currently thinking about and will tackle when I get time.</p>

<!-- more -->


<h2>Write up Stage</h2>

<h3>Reserve Constraints in co-optimised energy and security markets</h3>

<p>My first major piece of work which started it all. In an energy and reserve co-optimised market the total least cost solution for energy and security are dispatched. However, this can result in some quite non-intuitive dispatches and final pricing which is difficult to understand.
In particular, the merit order appears to be broken and final pricing can become disconnected from the energy offers.</p>

<p>This body of work discusses the theoretical mechanism through which this occurs. These theoretical mechanisms can be developed in two separate ways. Using the associate dual program (to the primal dispatch problem) or by developing small models which have a small subset of the constraints applied. I prefer the second approach as it is quite intuitive when visualising the solution upon a small model as compared to the mathematical result which arises. These constraints can occur in a number of different ways, and corner point solutions are also possible.</p>

<p>Finally, I apply the results to create a set of filters which can be applied to the New Zealand market to determine when constraints occur.
These filters are extremely effective (although transmission losses are an issue) at identifying the vast majority of the constrained periods. These results are illustrated as well as some discussion regarding the effect upon average prices discussed. The broad results is that security co-optimisation does not lead to any noticeable (long term) effect on energy prices although seasonal effects are apparent. However, these constraints have a major effect upon the average reserve market price and their resolution may severely reduce such pricing.</p>

<h3>Probabilistic models for assessing the frequency of reserve constrained events.</h3>

<p>This is a body of work which extends upon the reserve constraints I identified above. Broadly, it seeks to investigate the common causes and if possible develop a probabilistic approach to investigating when they might occur. Broadly, I assess the general factors which are related in Electricity markets, time of day, time of year, hydrology, demand, security availability and market risk. From these factors I choose a subset which I then develop into an extended model.</p>

<p>The model used inverse weighting of two smaller, more generic predictions. The inverse weighting method is used due to a dichotomy in the number of periods which exist at different hydrology levels. Using discrete bin sizes would lead to large errors and horribly distort the model. However, it was non-intuitive as to the best method of rectifying this. I settled on the inverse weighting approach as it appeared simple and elegant and accurately addressed my major concern.</p>

<p>The model develop shows great qualitative and adequate quantitative accuracy. These events in New Zealand are uncommon, happening between 2% and 10% of the total trading periods over the past five years (South Island market, North Island market respectively). Thus, any approach would provides an indication as to when they occur is very useful. Broadly, the model was able to predict when large numbers of constrained periods would occur, as well as when they would not. Such a result is a definitive increase compared to a simple naive average, furthermore it is an enhanced understanding over the raw (univariate) analysis initially conducted.</p>

<h3>On the non-linearity of consequences, why low probability events matter in Electricity networks.</h3>

<p>This is a short extended abstract and presentation which I&rsquo;m preparing for the U21 graduate conference in Dublin. The theme of the conference is Energy Policy and Systems. In this vein I&rsquo;ve decided to not speak about security constrained events and to take a more philosophical approach. One line of thought which I find fascinating is that some events are so catastrophic, so disastrous that people would pay almost any price to avoid them.</p>

<p>I extend this idea into the realm of Electricity markets and develop several case studies. These case studies explore the broad elements of non-linearity in bounded systems (e.g. how the system behaves as it approaches the bound, as well as the location of each bound) and discuss their importance. It is also extend to develop a non-linear tolerance between different participants in a system to highlight a dichotomy. The broad case studies discussed are:</p>

<ul>
<li>Cascade failure in Electrical networks leading to black starts</li>
<li>Extreme price distributions, 53% of revenue in the NZ security (secondary) market is made in 1% of the trading periods</li>
<li>Response to the Christchurch Earthquake of 2011 which highlighted different participants tolerance to network disruption.</li>
</ul>


<h2>In Progress Stage</h2>

<h3>Hedging via Reserve Markets</h3>

<p>This is an idea which I&rsquo;m currently developing regarding the effectiveness of partial hedging via the reserve markets. Broadly, such a measure is similar to a Financial Transmission Right (FTR). However, an FTR is far more comprehensive than the Reserve Hedge. The pertinent question to be answered would be the relative effectiveness of such a measure. This effectiveness will likely be measured by assessing the degree of cover afforded by such a hedge as well as the relative cost of such a measure.</p>

<p>I may be able to incorporate my probabilistic work into this to extend it into a dynamic hedging strategy. This could be undertaken along both perfect (full information and ability to hedge) and imperfect (heavily constrained) viewpoints. Either way, it will be an interesting assessment of how reserve markets can be linked into the energy markets. One measure which is not covered is that reserve hedging could be accomplished either physically or financially.</p>

<h2>Backburner Stage</h2>

<h3>Offer Strategies for participants during reserve constrained events.</h3>

<p>This will be more of a theoretical evaluation as to how optimal offer strategies begin to change when Reserve constraints are present in a market. These constraints will be assessed from a number of view points, e.g. generator, generator with reserve, reserve provider etc as to determine what the effect is on the margin. As there exists a linkage between the energy and reserve market prices during these events. Thus, it may be possible to highlight when a participant may be able to exert market power in one market to induce a constraint resulting in increased profits.</p>

<h3>Simulation study of the effect of reduced Transmission constraints upon Reserve and Enerfy pricing in New Zealand.</h3>

<p>My current body of work has shown that there exists a substantial relationship between the value of the security market and constraints. Broadly, the market is defined by extremely low median prices with very high priced tail events which occur extremely rarely. However, these events are linked to constraints which exist due to the configuration of the HVDC poles. With the commissioning of the new Pole it will be worthwhile to assess what effect this will have upon the marginal periods when electricity peakers and reserve providers expect to recover the majority of their costs.</p>

<h2>Code Projects</h2>

<h3>nzem</h3>

<p>This is intended mainly as a personal repository, but I will attempt to make it usable for others, which should investigate the ease of investigating the NZ electricity market. It currently has some broad helper functions but is currently in a bit of a haphazard space and needs a full rework soon. I&rsquo;ll try and put together a longer post explaining where I&rsquo;m intending to take this as well as highlighting what work needs to be done soon.</p>

<p>I also want to extend this module to help assess the NZ electricity hedge market including a better method of handling the data import and output. I&rsquo;ll attempt to get this started as soon as possible.</p>

<h3>pdtools</h3>

<p>pdtools is a repository which applies a few monkey patches to the Pandas DataFrame and Series objects. Currently it adds some useful (in my opinion) data selection functions to both DataFrames and Series as well as providing method to simplify merging series. This repository will contain the functions and shortcuts I find most useful when working with Pandas objects.</p>

<p>One thing which I do want to extend with this library is making the plotting and data output slightly nicer for including in publications. I find the default matplotlib styles a little ho-hum so I&rsquo;ll try and build some improve functionality into the repository to make the plots prettier. One other aspect is that I prefer a particular LaTeX table style when I&rsquo;m putting together tables so I&rsquo;ll include this as well.</p>

<h3>pyspd</h3>

<p>pyspd is a small repository which is intended to create small linear programs with the full complement of security and risk constraints in the NZ market. Broadly, it provides wrappers for setting up Nodes and generation stations without needing to understand how the underlying mathematics work. To do this it builds upon the puLP repository and the relevant solvers will be needed.</p>

<p>Currently this repository needs a lot of work to bring it up to scratch in the near future.</p>

<h2>Conclusion</h2>

<p>Well, this broadly covers everything I&rsquo;m working on professionally at the moment. There are a number of things which require my attention and it can be difficult juggling the time appropriately between them. In particular, I find when I get in a state of flow that I can crank out a large volume of highly productive and high quality work in a few hours. However, if I can&rsquo;t reach this state then it is difficult to be productive. One thing I&rsquo;m working on is trying to queue up work which can be done in less productive states (i.e. requiring little creativity or insight) so that I can still get things done. However, I appear to have had limited success at doing this so far.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Why Researchers should strive to develop repeatable code]]></title>
    <link href="http://NigelCleland.github.io/blog/2013/05/20/why-researchers-should-strive-to-develop-repeatable-code/"/>
    <updated>2013-05-20T11:06:00+12:00</updated>
    <id>http://NigelCleland.github.io/blog/2013/05/20/why-researchers-should-strive-to-develop-repeatable-code</id>
    <content type="html"><![CDATA[<p>As a researcher you&rsquo;ll often have to conduct a lot of smaller experiments, testing out a hypothesis here, running some data analysis there. Yet a lot of people I know, and I am personally guilty of this as well, do not make these scripts repeatable. Writing smart, testable, repeatable code takes longer and for many researchers who code out of necessity, not out of love it is not as intuitive. In many undergraduate degrees, particularly in engineering, the goal throughout the course of study is more to finish the assignment, pass the paper and repeatability be damned.</p>

<p>However, this behaviour becomes counterproductive once you start researching. I cannot imagine the number of hours I have wasting having to repeat useless boiler plate, hard coded examples when some intelligent preparation work, although taking a bit longer initially would save me far more time in the long run.</p>

<!-- more -->


<p>The temptation is to justify taking the quick route through the rational realisation that a lot of the code you write will often be thrown away. Therefore, what is the point in making sure it is repeatable if we may throw out the hypothesis and start again anyway? Here, focus upon the methods you are applying, know that data you are applying it to and take a couple lessons from functional programming.</p>

<p>For example, you may create a great hypothesis which works for your current set of data. However, you&rsquo;ve screwed up and hard coded a bunch of exceptions, magic numbers and other such parameters into the code. Elements you didn&rsquo;t need to. Wouldn&rsquo;t it be great if you could simply point your magical, world breaking, code at a new source of data and let the computer sort it all out?</p>

<p>In my opinion this is what researchers should be striving to do. To separate content and form so to speak from one another. If you are developing a model, generalise the parts of it and then set it up so they are easy to connect. The model itself should update itself depending upon what data you feed it and shouldn&rsquo;t be limited as such. By arbitrarily limiting it you&rsquo;re really just kicking yourself later on down the road.</p>

<p>So, how can we avoid screwing up, and start developing elegant repeatable code? Let&rsquo;s go through a couple options.</p>

<ul>
<li>Folder structure and file naming</li>
<li>Version Control</li>
<li>Smarter development of objects and functions</li>
<li>Modules and packages</li>
<li>Tests</li>
</ul>


<h2>Folder Structure and File Naming</h2>

<p>Folder structure, or directory layout, seems like a strange thing to be placing upon a list of developing elegant code. Same with file naming. So what does this have to do with research and developing code? Quite simply a lot. Let&rsquo;s talk about the initial folder layout I use a simple three tier approach as follows.</p>

<p>Note, that here the data is for trivial examples. If you&rsquo;re using anything more complex then I highly recommend you start researching into Databases and whether your data is suitable for them. However, one caveat is that introducing a Database layer may add significant overhead and if you are unskilled this may be beyond you. Nonetheless, give it a try, see if you like it. As a general rule of thumb think about how much information you are needing to store. 10 MB, you may be okay with a file. 100 MB, pushing it, possibly okay if you&rsquo;re using a library like pandas and vectorised calculations. 1000 MB, Databases start becoming your friend very very quickly. Additionally, you should ask yourself whether other people will also need access to the data sources.</p>

<p>```
data</p>

<pre><code>- set_one
- set_two
</code></pre>

<p>scripts</p>

<pre><code>- experiment_one
- experiment_two
</code></pre>

<p>modules</p>

<pre><code>- module_one
- module_two
</code></pre>

<p>```</p>

<p>Now, what I&rsquo;ve done is I&rsquo;ve completed separated the three key aspects of my work. All of my data is contained within its own folder. I don&rsquo;t touch it and I certainly don&rsquo;t change any of the files within once they&rsquo;ve been modified. What this ensures is that if I chose to repeat something I can be sure that my dataset hasn&rsquo;t changed, and that assuming that the code has changed my program and code should just <em>work</em>.</p>

<p>Secondly, I&rsquo;ve separated out my scripts and modules. Here we should define what each is. A module is something you&rsquo;ve developed which is testable and method independent. It may be a package you&rsquo;ve got off <a href="github.com">github</a> or something you&rsquo;ve developed yourself, such as a useful package of <a href="github.com/NigelCleland/pdtools">tools</a>. Now, your scripts on the other hand are the nitty gritty of what you do. You can still write these in a terrible fashion however at least the tools you use, and the data you run it on should be easily separable.</p>

<h2>Version Control</h2>

<p>What is Version Control and why, as a researcher, do I care? Ever worked with other people and what ends up getting passed around is a ton of files with names such as <code>file_name_person_number_44_date_37_final_copy_3.ext</code>. If yes, and if this made you absolutely hate life and become seriously concerned about the future well being of the human race then version control is for you!
Now, I recommend using what people are comfortable with, however if you&rsquo;re new to it then my recommendation is to pick up git.</p>

<p>Git is a decentralised version control system which makes merging together branches etc easy. Don&rsquo;t know what any of that means? Then pick up a copy of the progit book from github and get reading. I&rsquo;m not going to go through all of the nitty gritty here, just to say that you should be using it and if you&rsquo;re not then file name hell may be for you! Importantly, version control lets you do as the name suggests and manage different versions of something in a sane easy to implement manner. What is great about it is if you use a plain text based document system, such as LaTeX then you can also manage your documents with it. This makes storing different versions simple (e.g. define a branch as 0.1.0) and you&rsquo;ll always be able to return to that branch for prior iterations.</p>

<h2>Smarter development of objects and functions</h2>

<p>Whenever you need to hard code something in to your scripts you should ask yourself. Do I really need to be doing this? Is there a better way? Can I write this in such a way that I will understand it a week from now, a month from now? Code should be written so that it is easy for you to understand, not the machine. If at a later point you need something to be faster then by all means start optimising things (e.g. move towards C). However, initially write it so that you can understand it. Only rewrite the truly performance critical parts.</p>

<p>Here things which help include, keyword arguments instead of hard coded parameters. Comments, docstrings, shorter functions. Resist the urge to develop so called &ldquo;God&rdquo; functions or classes that do everything. Instead, separate these (where sensible) into smaller reusable functions or methods. Obviously this is context specific and I&rsquo;m not going to give too many specifics.</p>

<p>Just imagine future you is standing behind you with a shotgun and will pull the trigger if he doesn&rsquo;t understand what, or why, you are doing something in particular which is undocumented. The other key element here is to avoid, where possible, scope creep.</p>

<p>Don&rsquo;t just randomly and haphazardly add new methods, or functions to a script and make it do something completely unexpected because it was easier at the time. Separate out the components and then join them together in an intelligent fashion.</p>

<h2>Modules and packages</h2>

<p>Modules and packages are simply reusable code. They&rsquo;re broadly use case independent and are therefore fantastic for saving time. There are hundreds of packages out there which will simplify your life and make you more productive. My advice is to use them.</p>

<p>My second piece of advice is to take those functions which you use again and again and create your own custom packages. You don&rsquo;t have to release this to the general public but a toolbox which makes your life far far easier is not something to be dismissed. The code you write which goes into your module should be the best code you&rsquo;ve written. You&rsquo;re going to be using it hundreds of times and you want to know exactly what it will do in all situations.</p>

<h2>Tests</h2>

<p>Finally we come to the worst aspect of coding from my personal point of view. I know some people love writing tests, and enjoy test driven methodology however I see a key difference here. A lot of the people who enjoy test driven coding are writing software. In research we&rsquo;re often developing a number of small scripts which we use to generate results. Quite simply we don&rsquo;t have the same sense of scale, or requirements, as other programmers.</p>

<p>Therefore, where are tests useful? Tests are most useful in your modules and packages, and less useful in your custom scripts. My general rule of thumb is as follows, if I&rsquo;m going to use this in multiple places and multiple situations then I am going to want a test for each of those places and situations. If I don&rsquo;t do this then I may make a modification for one particular use case forgetting that you&rsquo;re depending upon the previous functionality for a separate usecase. A test, if implemented and properly, would catch this behaviour and you can hopefully develop smarter.</p>

<p>However, the key element here is that you&rsquo;re reusing code. If you are using it once, in a very specific situation then the code itself almost becomes a test. If it works, then the function is correct. If it doesn&rsquo;t work, the function is wrong. As there is only one use case is there much value in developing a test which repeats our use case?</p>

<h2>Conclusions</h2>

<p>In this post I&rsquo;ve argued, and laid out a few examples, of why and how you should be writing more repeatable code as a researcher. The list is by no means complete and is still a work in progress. I am after all still learning how to write better code, something which will continue as long as I am writing code.</p>

<p>Feel free to ask any questions in the comments.</p>
]]></content>
  </entry>
  
</feed>
